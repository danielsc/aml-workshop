{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Azure IDs used for this workshop\n",
    "```python\n",
    "subscription_id='4feb84f6-2c10-4536-9c8a-0a2360eabfc5'\n",
    "resource_group='azureml'\n",
    "container_registry='/subscriptions/4feb84f6-2c10-4536-9c8a-0a2360eabfc5/resourcegroups/azureml/providers/microsoft.containerregistry/registries/danielscacrcvsldmti'\n",
    "location='westeurope'\n",
    "```\n",
    "\n",
    "## Slides\n",
    "\n",
    "https://aka.ms/aifetalk\n",
    "\n",
    "## Setup\n",
    "\n",
    "1. Install the VS Code extension at : https://msasg.visualstudio.com/OpenMind%20Studio/OpenMind%20Studio%20Team/_build/results?buildId=3354388\n",
    "Make sure it has a recent version of the Python SDK -- remove the folder ~/.azureml/envs if there are issuse. A current SDK will be installed when you first use AML from VSCode.\n",
    "2. Install the Python SDK: https://github.com/Azure/ViennaDocs/tree/master/PrivatePreview\n",
    "    make sure to install automl, notebook, and contrib\n",
    "\n",
    "```shell\n",
    "source activate py36\n",
    "pip install --upgrade azureml-sdk[notebooks,contrib,automl] --user\n",
    "jupyter nbextension install --py --user azureml.train.widgets\n",
    "jupyter nbextension enable azureml.train.widgets --user --py\n",
    "\n",
    "```\n",
    "You will need to restart jupyter after this\n",
    "3. Clone this repository\n",
    "```shell\n",
    "git clone https://github.com/danielsc/aml-workshop\n",
    "jupyter notebook\n",
    "```\n",
    "\n",
    "## Before each demo\n",
    "* Create a new, empty notebook in the ignite directory of the repo\n",
    "* if you have run this before, make sure you delete mnist_with_summaries.py from the folder ignite_demo\n",
    "* open VSCode at the ignite_demo directory\n",
    "* go to ignite directory and start jupyter notebook there\n",
    "* make sure to bring up the cluster by going to the Azure portal\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## F1 Download Tensorflow  demo code (we will just do this in the browser)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "source_folder = './demo'\n",
    "import requests\n",
    "import os\n",
    "tf_code = requests.get(\"https://raw.githubusercontent.com/tensorflow/tensorflow/r1.8/tensorflow/examples/tutorials/mnist/mnist_with_summaries.py\")\n",
    "with open(os.path.join(source_folder, \"mnist_with_summaries.py\"), \"w\") as file:\n",
    "    file.write(tf_code.text)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## run the script locally "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "!/anaconda/envs/py36/bin/python demo/mnist_with_summaries.py\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## F2 make sure we import everything -- makes for faster typing and intellisense"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SDK version: 0.1.68\n"
     ]
    }
   ],
   "source": [
    "from azureml.train.dnn import TensorFlow\n",
    "from azureml.contrib.tensorboard import Tensorboard\n",
    "from azureml.core import Workspace, Experiment\n",
    "from azureml.core.compute import ComputeTarget, BatchAiCompute\n",
    "from azureml.train.widgets import RunDetails\n",
    "from azureml.train.hyperdrive import *\n",
    "from azureml.train.automl import AutoMLConfig\n",
    "from azureml.train.automl.constants import Metric\n",
    "from demo.get_data import get_data\n",
    "import time\n",
    "import azureml.core\n",
    "import math, os\n",
    "\n",
    "source_folder = './demo'\n",
    "print(\"SDK version:\", azureml.core.VERSION)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## F3 This is how you create a workspace\n",
    "we are explicitly setting the container registry to an existing one to avoid\n",
    "image creation during the workshop (image creation taks 3-8 minutes depending on size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ws = Workspace.create(name=<<your_alias_here>>, \n",
    "                      subscription_id='4feb84f6-2c10-4536-9c8a-0a2360eabfc5', \n",
    "                      resource_group='azureml', \n",
    "                      container_registry='/subscriptions/4feb84f6-2c10-4536-9c8a-0a2360eabfc5/resourcegroups/azureml/providers/microsoft.containerregistry/registries/danielscacrcvsldmti',\n",
    "                      location='westeurope',\n",
    "                      exist_ok=True)\n",
    "ws.name"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "ws = Workspace.get(name='<<your_alias_here>>', subscription_id='4feb84f6-2c10-4536-9c8a-0a2360eabfc5', resource_group='azureml')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## F4 This is how you create a batch AI cluster\n",
    "we are setting min_nodes to 2 to have save us the preparation time for each job -- **make sure to dial this down after the workshop**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#                                                                            Standard_NC6s_v2\n",
    "provisioning_config = BatchAiCompute.provisioning_configuration(vm_size = \"Standard_NC6\",\n",
    "                                                                autoscale_enabled = True,\n",
    "                                                                cluster_min_nodes = 2, \n",
    "                                                                cluster_max_nodes = 20)\n",
    "\n",
    "p100cluster = ComputeTarget.create(ws, \n",
    "                                   name = \"p100cluster\", \n",
    "                                   provisioning_configuration=provisioning_config)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "p100cluster.refresh_state()\n",
    "p100cluster.provisioning_state\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "p100cluster.refresh_state()\n",
    "p100cluster.status.node_state_counts.serialize()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "p100cluster = ws.compute_targets()['p100cluster']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## F5 let's create an experiment in VSCode and then retrieve it here"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "mnist = Experiment(ws, 'linkedin')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## F6 now we run the script on our cluster, tracked in the mnist Experiment\n",
    "\n",
    "(what is an estimator, how is tensorflow different, what other estimators are there?)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "tf_estimator = TensorFlow(source_directory=source_folder,\n",
    "                          compute_target=p100cluster,\n",
    "                          entry_script='mnist_with_summaries.py')\n",
    "\n",
    "run = mnist.submit(tf_estimator)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## F7 How can we monitor the experiment?\n",
    "\n",
    "If you don't see the widget, you will need to\n",
    "\n",
    "1. stop jupyter\n",
    "2. run the following\n",
    "```\n",
    "    jupyter nbextension install --py --user azureml.train.widgets\n",
    "    jupyter nbextension enable azureml.train.widgets --user --py\n",
    "```\n",
    "3. start jupyter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a9ffbcfea8a846079fced9003361118f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "_UserRun(widget_settings={'childWidgetDisplay': 'popup'})"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "RunDetails(run).show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Let's visualize the Accuracy so we can better see the progress of the training run"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1. add this at the top of the file\n",
    "```python\n",
    "    from azureml.core.run import Run\n",
    "```\n",
    "2. add 'Run.get_submitted....' near line 165, so you get this\n",
    "```python\n",
    "    print('Accuracy at step %s: %s' % (i, acc))\n",
    "    if i % 50 == 0:\n",
    "        Run.get_submitted_run().log('Accuracy_test', acc)\n",
    "```\n",
    "3. add the same line with different log name further down\n",
    "```python\n",
    "    test_writer.close()\n",
    "    Run.get_submitted_run().log('Accuracy', acc)\n",
    "```\n",
    "\n",
    "4. and add this to log the parameters chosen at the end of the file\n",
    "```python\n",
    "    FLAGS, unparsed = parser.parse_known_args()\n",
    "    Run.get_submitted_run().log('learning_rate', FLAGS.learning_rate)\n",
    "    Run.get_submitted_run().log('dropout', FLAGS.dropout)\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## F10 copy the the script over"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'./demo/mnist_with_summaries.py'"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Or just run this cell\n",
    "from  shutil import copyfile\n",
    "copyfile('../misc/mnist_with_summaries.py', os.path.join(source_folder, 'mnist_with_summaries.py'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## F11 run the same way as above"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "7abfaf9aec2141c59535b76037093426",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "_UserRun(widget_settings={'childWidgetDisplay': 'popup'})"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "tf_estimator = TensorFlow(source_directory=source_folder,\n",
    "                          compute_target=p100cluster,\n",
    "                          entry_script='mnist_with_summaries.py')\n",
    "\n",
    "run = mnist.submit(tf_estimator)\n",
    "RunDetails(run).show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## F12 wasn't there another way to visualize the metrics of a model? Tensorboard."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "2b529baaf8ad4cf59c89ce0ff7d417d0",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "_UserRun(widget_settings={'childWidgetDisplay': 'popup'})"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# just add the log_dir parameter\n",
    "script_params={\n",
    "    '--log_dir': './logs',\n",
    "}\n",
    "\n",
    "tf_estimator = TensorFlow(source_directory=source_folder,\n",
    "                          compute_target=p100cluster,\n",
    "                          entry_script='mnist_with_summaries.py',\n",
    "                          script_params=script_params)\n",
    "\n",
    "run = mnist.submit(tf_estimator)\n",
    "RunDetails(run).show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Start Tensorboard\n",
    "\n",
    "Now, while the run is in progress, we just need to start Tensorboard with the run as its target, and it will begin streaming logs."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "http://danielsc:6006\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'http://danielsc:6006'"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tb = Tensorboard(run)\n",
    "tb.start()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Stop Tensorboard\n",
    "\n",
    "When you're done, make sure to call the `stop()` method of the Tensorboard object, or it will stay running even after your job completes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tb.stop()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## F8 But, what if my data is not sitting somewhere on the internet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ds = ws.get_default_datastore()\n",
    "mnist_data = ds.upload(src_dir = '/Users/danielsc/data/mnist', target_path = 'mnist', show_progress = True)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## F9 Run the same as above but with script_param pointing to the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# run the same was as above\n",
    "script_params={\n",
    "    '--log_dir': './logs',\n",
    "    '--data_dir': mnist_data,\n",
    "}\n",
    "\n",
    "tf_estimator = TensorFlow(source_directory=source_folder,\n",
    "                          compute_target=p100cluster,\n",
    "                          entry_script='mnist_with_summaries.py',\n",
    "                          script_params=script_params)\n",
    "\n",
    "run = mnist.submit(tf_estimator)\n",
    "RunDetails(run).show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Hyperparameter tuning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# same as above but increase the max_steps and remove the parameters\n",
    "script_params={\n",
    "    '--log_dir': './logs',\n",
    "    '--data_dir': mnist_data,\n",
    "    '--max_steps': 5000\n",
    "}\n",
    "\n",
    "tf_estimator = TensorFlow(source_directory=source_folder,\n",
    "                          compute_target=p100cluster,\n",
    "                          entry_script='mnist_with_summaries.py',\n",
    "                          script_params=script_params)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. kicking of the job"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "ps = RandomParameterSampling(\n",
    "    {\n",
    "        '--learning_rate': loguniform(-15, -3),\n",
    "        '--dropout': uniform(0.5, 0.95)\n",
    "    }\n",
    ")\n",
    "\n",
    "early_termination_policy = BanditPolicy(slack_factor = 0.15, evaluation_interval=2)\n",
    "\n",
    "hyperdrive_run_config = HyperDriveRunConfig(estimator = tf_estimator, \n",
    "                                            hyperparameter_sampling = ps, \n",
    "                                            policy = early_termination_policy,\n",
    "                                            primary_metric_name = \"Accuracy_test\",\n",
    "                                            primary_metric_goal = PrimaryMetricGoal.MAXIMIZE,\n",
    "                                            max_total_runs = 20,\n",
    "                                            max_concurrent_runs = 5)\n",
    "\n",
    "hd_run = mnist.submit(hyperdrive_run_config)\n",
    "\n",
    "RunDetails(hd_run).show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 7. What if I don't know what type of model to choose?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "automl_config = AutoMLConfig(task = 'classification',\n",
    "                             path=source_folder,\n",
    "                             compute_target = p100cluster,\n",
    "                             data_script = source_folder + \"/get_data.py\",\n",
    "                             max_time_sec = 600,\n",
    "                             iterations = 20,\n",
    "                             n_cross_validations = 5,\n",
    "                             primary_metric = Metric.AUCWeighted,\n",
    "                             concurrent_iterations = 10)\n",
    "\n",
    "remote_run = mnist.submit(automl_config)\n",
    "\n",
    "RunDetails(remote_run).show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "from azureml.train.automl import AutoMLConfig\n",
    "from azureml.train.automl.constants import Metric\n",
    "from ignite_demo.get_data import get_data\n",
    "import time, logging\n",
    "\n",
    "\n",
    "automl_config = AutoMLConfig(task = 'classification',\n",
    "                             debug_log = 'automl_errors.log',\n",
    "                             primary_metric = 'AUC_weighted',\n",
    "                             iterations = 10,\n",
    "                             n_cross_validations = 3,\n",
    "                             verbosity = logging.INFO,\n",
    "                             X = get_data()['X'], \n",
    "                             y = get_data()['y'],\n",
    "                             max_cores_per_iteration = 1,\n",
    "                             enforce_time_on_windows = False,\n",
    "                             path=source_folder)\n",
    "\n",
    "local_run = mnist.submit(automl_config, show_output=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.6 - AzureML",
   "language": "python",
   "name": "python3-azureml"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
